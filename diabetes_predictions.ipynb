{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1ba601-5721-4fa9-8bb5-ce36ed2f2fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "62/62 [==============================] - 1s 1ms/step - loss: 0.6785 - accuracy: 0.6254\n",
      "Epoch 2/160\n",
      "62/62 [==============================] - 0s 992us/step - loss: 0.6629 - accuracy: 0.6515\n",
      "Epoch 3/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6596\n",
      "Epoch 4/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.6531\n",
      "Epoch 5/160\n",
      "62/62 [==============================] - 0s 989us/step - loss: 0.6295 - accuracy: 0.6515\n",
      "Epoch 6/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.6726\n",
      "Epoch 7/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6694\n",
      "Epoch 8/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.6775\n",
      "Epoch 9/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.6775\n",
      "Epoch 10/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.6906\n",
      "Epoch 11/160\n",
      "62/62 [==============================] - 0s 977us/step - loss: 0.5918 - accuracy: 0.6759\n",
      "Epoch 12/160\n",
      "62/62 [==============================] - 0s 993us/step - loss: 0.5894 - accuracy: 0.6922\n",
      "Epoch 13/160\n",
      "62/62 [==============================] - 0s 993us/step - loss: 0.5825 - accuracy: 0.7052\n",
      "Epoch 14/160\n",
      "62/62 [==============================] - 0s 958us/step - loss: 0.5906 - accuracy: 0.6906\n",
      "Epoch 15/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5781 - accuracy: 0.6987\n",
      "Epoch 16/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7329\n",
      "Epoch 17/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5658 - accuracy: 0.7362\n",
      "Epoch 18/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5709 - accuracy: 0.7068\n",
      "Epoch 19/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.5646 - accuracy: 0.7117\n",
      "Epoch 20/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7101\n",
      "Epoch 21/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.7296\n",
      "Epoch 22/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.7248\n",
      "Epoch 23/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7248\n",
      "Epoch 24/160\n",
      "62/62 [==============================] - 0s 987us/step - loss: 0.5589 - accuracy: 0.7443\n",
      "Epoch 25/160\n",
      "62/62 [==============================] - 0s 969us/step - loss: 0.5536 - accuracy: 0.7199\n",
      "Epoch 26/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7362\n",
      "Epoch 27/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7215\n",
      "Epoch 28/160\n",
      "62/62 [==============================] - 0s 990us/step - loss: 0.5460 - accuracy: 0.7394\n",
      "Epoch 29/160\n",
      "62/62 [==============================] - 0s 952us/step - loss: 0.5502 - accuracy: 0.7264\n",
      "Epoch 30/160\n",
      "62/62 [==============================] - 0s 972us/step - loss: 0.5527 - accuracy: 0.7248\n",
      "Epoch 31/160\n",
      "62/62 [==============================] - 0s 987us/step - loss: 0.5413 - accuracy: 0.7492\n",
      "Epoch 32/160\n",
      "62/62 [==============================] - 0s 992us/step - loss: 0.5410 - accuracy: 0.7443\n",
      "Epoch 33/160\n",
      "62/62 [==============================] - 0s 991us/step - loss: 0.5375 - accuracy: 0.7557\n",
      "Epoch 34/160\n",
      "62/62 [==============================] - 0s 992us/step - loss: 0.5490 - accuracy: 0.7362\n",
      "Epoch 35/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.7394\n",
      "Epoch 36/160\n",
      "62/62 [==============================] - 0s 988us/step - loss: 0.5496 - accuracy: 0.7296\n",
      "Epoch 37/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.7557\n",
      "Epoch 38/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7394\n",
      "Epoch 39/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7492\n",
      "Epoch 40/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5374 - accuracy: 0.7182\n",
      "Epoch 41/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7476\n",
      "Epoch 42/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.7573\n",
      "Epoch 43/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7606\n",
      "Epoch 44/160\n",
      "62/62 [==============================] - 0s 985us/step - loss: 0.5305 - accuracy: 0.7590\n",
      "Epoch 45/160\n",
      "62/62 [==============================] - 0s 972us/step - loss: 0.5268 - accuracy: 0.7508\n",
      "Epoch 46/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.7443\n",
      "Epoch 47/160\n",
      "62/62 [==============================] - 0s 987us/step - loss: 0.5280 - accuracy: 0.7557\n",
      "Epoch 48/160\n",
      "62/62 [==============================] - 0s 953us/step - loss: 0.5220 - accuracy: 0.7590\n",
      "Epoch 49/160\n",
      "62/62 [==============================] - 0s 957us/step - loss: 0.5224 - accuracy: 0.7476\n",
      "Epoch 50/160\n",
      "62/62 [==============================] - 0s 988us/step - loss: 0.5294 - accuracy: 0.7459\n",
      "Epoch 51/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.7329\n",
      "Epoch 52/160\n",
      "62/62 [==============================] - 0s 993us/step - loss: 0.5239 - accuracy: 0.7459\n",
      "Epoch 53/160\n",
      "62/62 [==============================] - 0s 813us/step - loss: 0.5195 - accuracy: 0.7541\n",
      "Epoch 54/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7622\n",
      "Epoch 55/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.7459\n",
      "Epoch 56/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7427\n",
      "Epoch 57/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.7476\n",
      "Epoch 58/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5221 - accuracy: 0.7606\n",
      "Epoch 59/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.7557\n",
      "Epoch 60/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7492\n",
      "Epoch 61/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5139 - accuracy: 0.7557\n",
      "Epoch 62/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5110 - accuracy: 0.7508\n",
      "Epoch 63/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7557\n",
      "Epoch 64/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5196 - accuracy: 0.7524\n",
      "Epoch 65/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5174 - accuracy: 0.7573\n",
      "Epoch 66/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5171 - accuracy: 0.7541\n",
      "Epoch 67/160\n",
      "62/62 [==============================] - 0s 951us/step - loss: 0.5201 - accuracy: 0.7476\n",
      "Epoch 68/160\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.5045 - accuracy: 0.7622\n",
      "Epoch 69/160\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.5189 - accuracy: 0.7476\n",
      "Epoch 70/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.5181 - accuracy: 0.7492\n",
      "Epoch 71/160\n",
      "62/62 [==============================] - 0s 951us/step - loss: 0.5073 - accuracy: 0.7655\n",
      "Epoch 72/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5068 - accuracy: 0.7720\n",
      "Epoch 73/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5109 - accuracy: 0.7508\n",
      "Epoch 74/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.5107 - accuracy: 0.7459\n",
      "Epoch 75/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.5155 - accuracy: 0.7557\n",
      "Epoch 76/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.5108 - accuracy: 0.7606\n",
      "Epoch 77/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.5046 - accuracy: 0.7638\n",
      "Epoch 78/160\n",
      "62/62 [==============================] - 0s 951us/step - loss: 0.5024 - accuracy: 0.7655\n",
      "Epoch 79/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4986 - accuracy: 0.7606\n",
      "Epoch 80/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.5013 - accuracy: 0.7590\n",
      "Epoch 81/160\n",
      "62/62 [==============================] - 0s 951us/step - loss: 0.5075 - accuracy: 0.7606\n",
      "Epoch 82/160\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.5012 - accuracy: 0.7606\n",
      "Epoch 83/160\n",
      "62/62 [==============================] - 0s 951us/step - loss: 0.5068 - accuracy: 0.7590\n",
      "Epoch 84/160\n",
      "62/62 [==============================] - 0s 951us/step - loss: 0.4999 - accuracy: 0.7655\n",
      "Epoch 85/160\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.5026 - accuracy: 0.7557\n",
      "Epoch 86/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7557\n",
      "Epoch 87/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7655\n",
      "Epoch 88/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7687\n",
      "Epoch 89/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7655\n",
      "Epoch 90/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4939 - accuracy: 0.7818\n",
      "Epoch 91/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7769\n",
      "Epoch 92/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4933 - accuracy: 0.7638\n",
      "Epoch 93/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4860 - accuracy: 0.7752\n",
      "Epoch 94/160\n",
      "62/62 [==============================] - 0s 784us/step - loss: 0.4855 - accuracy: 0.7704\n",
      "Epoch 95/160\n",
      "62/62 [==============================] - 0s 769us/step - loss: 0.4871 - accuracy: 0.7720\n",
      "Epoch 96/160\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.4912 - accuracy: 0.7736\n",
      "Epoch 97/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7606\n",
      "Epoch 98/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7720\n",
      "Epoch 99/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7720\n",
      "Epoch 100/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7736\n",
      "Epoch 101/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7671\n",
      "Epoch 102/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7671\n",
      "Epoch 103/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7769\n",
      "Epoch 104/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7785\n",
      "Epoch 105/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7720\n",
      "Epoch 106/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7834\n",
      "Epoch 107/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7606\n",
      "Epoch 108/160\n",
      "62/62 [==============================] - 0s 758us/step - loss: 0.4682 - accuracy: 0.7752\n",
      "Epoch 109/160\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.4719 - accuracy: 0.7801\n",
      "Epoch 110/160\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.4740 - accuracy: 0.7866\n",
      "Epoch 111/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7785\n",
      "Epoch 112/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7769\n",
      "Epoch 113/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7655\n",
      "Epoch 114/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7850\n",
      "Epoch 115/160\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.4722 - accuracy: 0.7720\n",
      "Epoch 116/160\n",
      "62/62 [==============================] - 0s 768us/step - loss: 0.4650 - accuracy: 0.7866\n",
      "Epoch 117/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7850\n",
      "Epoch 118/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7752\n",
      "Epoch 119/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7834\n",
      "Epoch 120/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7850\n",
      "Epoch 121/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7948\n",
      "Epoch 122/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7883\n",
      "Epoch 123/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7850\n",
      "Epoch 124/160\n",
      "62/62 [==============================] - 0s 861us/step - loss: 0.4633 - accuracy: 0.7834\n",
      "Epoch 125/160\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7801\n",
      "Epoch 126/160\n",
      "62/62 [==============================] - 0s 988us/step - loss: 0.4582 - accuracy: 0.7883\n",
      "Epoch 127/160\n",
      "62/62 [==============================] - 0s 979us/step - loss: 0.4662 - accuracy: 0.7834\n",
      "Epoch 128/160\n",
      "62/62 [==============================] - 0s 974us/step - loss: 0.4574 - accuracy: 0.7980\n",
      "Epoch 129/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4551 - accuracy: 0.7883\n",
      "Epoch 130/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4514 - accuracy: 0.7883\n",
      "Epoch 131/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4554 - accuracy: 0.7883\n",
      "Epoch 132/160\n",
      "62/62 [==============================] - 0s 963us/step - loss: 0.4639 - accuracy: 0.7785\n",
      "Epoch 133/160\n",
      "62/62 [==============================] - 0s 959us/step - loss: 0.4530 - accuracy: 0.7964\n",
      "Epoch 134/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4546 - accuracy: 0.7801\n",
      "Epoch 135/160\n",
      "62/62 [==============================] - 0s 957us/step - loss: 0.4534 - accuracy: 0.7866\n",
      "Epoch 136/160\n",
      "62/62 [==============================] - 0s 944us/step - loss: 0.4471 - accuracy: 0.7883\n",
      "Epoch 137/160\n",
      "62/62 [==============================] - 0s 960us/step - loss: 0.4431 - accuracy: 0.7932\n",
      "Epoch 138/160\n",
      "62/62 [==============================] - 0s 963us/step - loss: 0.4560 - accuracy: 0.7785\n",
      "Epoch 139/160\n",
      "62/62 [==============================] - 0s 945us/step - loss: 0.4428 - accuracy: 0.8029\n",
      "Epoch 140/160\n",
      "62/62 [==============================] - 0s 970us/step - loss: 0.4600 - accuracy: 0.7834\n",
      "Epoch 141/160\n",
      "62/62 [==============================] - 0s 936us/step - loss: 0.4459 - accuracy: 0.7964\n",
      "Epoch 142/160\n",
      "62/62 [==============================] - 0s 949us/step - loss: 0.4652 - accuracy: 0.7671\n",
      "Epoch 143/160\n",
      "62/62 [==============================] - 0s 947us/step - loss: 0.4499 - accuracy: 0.7769\n",
      "Epoch 144/160\n",
      "62/62 [==============================] - 0s 934us/step - loss: 0.4572 - accuracy: 0.7866\n",
      "Epoch 145/160\n",
      "62/62 [==============================] - 0s 938us/step - loss: 0.4546 - accuracy: 0.7818\n",
      "Epoch 146/160\n",
      "62/62 [==============================] - 0s 956us/step - loss: 0.4422 - accuracy: 0.7899\n",
      "Epoch 147/160\n",
      "62/62 [==============================] - 0s 941us/step - loss: 0.4362 - accuracy: 0.7834\n",
      "Epoch 148/160\n",
      "62/62 [==============================] - 0s 976us/step - loss: 0.4529 - accuracy: 0.7883\n",
      "Epoch 149/160\n",
      "62/62 [==============================] - 0s 982us/step - loss: 0.4474 - accuracy: 0.7818\n",
      "Epoch 150/160\n",
      "62/62 [==============================] - 0s 995us/step - loss: 0.4433 - accuracy: 0.7883\n",
      "Epoch 151/160\n",
      "62/62 [==============================] - 0s 971us/step - loss: 0.4435 - accuracy: 0.7915\n",
      "Epoch 152/160\n",
      "62/62 [==============================] - 0s 984us/step - loss: 0.4406 - accuracy: 0.7980\n",
      "Epoch 153/160\n",
      "62/62 [==============================] - 0s 979us/step - loss: 0.4392 - accuracy: 0.7818\n",
      "Epoch 154/160\n",
      "62/62 [==============================] - 0s 951us/step - loss: 0.4457 - accuracy: 0.7818\n",
      "Epoch 155/160\n",
      "62/62 [==============================] - 0s 946us/step - loss: 0.4488 - accuracy: 0.7964\n",
      "Epoch 156/160\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4354 - accuracy: 0.7964\n",
      "Epoch 157/160\n",
      "62/62 [==============================] - 0s 964us/step - loss: 0.4424 - accuracy: 0.7997\n",
      "Epoch 158/160\n",
      "62/62 [==============================] - 0s 960us/step - loss: 0.4372 - accuracy: 0.8013\n",
      "Epoch 159/160\n",
      "62/62 [==============================] - 0s 949us/step - loss: 0.4306 - accuracy: 0.8046\n",
      "Epoch 160/160\n",
      "62/62 [==============================] - 0s 947us/step - loss: 0.4350 - accuracy: 0.7850\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7403\n",
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Implement Neural Net using Keras Sequential model\n",
    "# Predict the onset of Diabetes for the Pima Indians based on \n",
    "# the available diagnostic data\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Import Pandas, Tensorflow, Sequential and Dense from Keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Read the csv file\n",
    "diabetes = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "diabetes.isnull().sum(axis=0)\n",
    "\n",
    "\n",
    "# Create X and Y variables\n",
    "X = diabetes.iloc[:, 0:-1]\n",
    "Y = diabetes.iloc[:,   -1]\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "    train_test_split(X, Y, test_size=0.2, random_state=1234, stratify=Y)\n",
    "\n",
    "\n",
    "# Define the keras sequential model with three hidden layers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(24,\n",
    "                input_shape=(8,),\n",
    "                activation='relu',\n",
    "                kernel_initializer='RandomNormal'))\n",
    "\n",
    "\n",
    "model.add(Dense(12,\n",
    "                activation='relu',\n",
    "                kernel_initializer='RandomNormal'))\n",
    "\n",
    "\n",
    "model.add(Dense(1,\n",
    "                activation='sigmoid',\n",
    "                kernel_initializer='RandomNormal'))\n",
    "\n",
    "\n",
    "# Compile the keras model for classification accuracy\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model on the training dataset\n",
    "model.fit(X_train, Y_train, epochs=160, batch_size=10)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = model.evaluate(X_test, Y_test)\n",
    "\n",
    "\n",
    "# Get the predicted probabilities and predicted classes\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "predictions = (Y_pred_prob > 0.5).astype('int32')\n",
    "\n",
    "\n",
    "# Create the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25b2288-dbda-4d68-8a22-16c7d7a920d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
